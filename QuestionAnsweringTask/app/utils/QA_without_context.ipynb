{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Zakaria-Laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Zakaria-Laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Zakaria-Laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Zakaria-Laptop\\AppData\\Local\\Temp\\ipykernel_23756\\1323145366.py\", line 3, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\torch\\__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\Zakaria-Laptop\\LLM-Models\\QuestionAnsweringTask\\myenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Les paths de fichiers\u001b[39;00m\n\u001b[0;32m      8\u001b[0m path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mZakaria-Laptop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLLM-Models\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNLP_TFIDF\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataBase\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS08_question_answer_pairs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Les paths de fichiers\n",
    "path1 = r\"C:\\Users\\Zakaria-Laptop\\LLM-Models\\NLP_TFIDF\\DataBase\\S08_question_answer_pairs.txt\"\n",
    "path2 = r\"C:\\Users\\Zakaria-Laptop\\LLM-Models\\NLP_TFIDF\\DataBase\\S09_question_answer_pairs.txt\"\n",
    "path3 = r\"C:\\Users\\Zakaria-Laptop\\LLM-Models\\NLP_TFIDF\\DataBase\\S10_question_answer_pairs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>DifficultyFromQuestioner</th>\n",
       "      <th>DifficultyFromAnswerer</th>\n",
       "      <th>ArticleFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months</td>\n",
       "      <td>medium</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months.</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>When did Lincoln begin his political career?</td>\n",
       "      <td>1832</td>\n",
       "      <td>medium</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleTitle                                       Question      Answer  \\\n",
       "6  Abraham_Lincoln  How many long was Lincoln's formal education?   18 months   \n",
       "7  Abraham_Lincoln  How many long was Lincoln's formal education?  18 months.   \n",
       "8  Abraham_Lincoln   When did Lincoln begin his political career?        1832   \n",
       "\n",
       "  DifficultyFromQuestioner DifficultyFromAnswerer  ArticleFile  \n",
       "6                   medium                   easy  S08_set3_a4  \n",
       "7                   medium                 medium  S08_set3_a4  \n",
       "8                   medium                   easy  S08_set3_a4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"    \n",
    "    return pd.read_csv(path, sep=\"\t\")\n",
    "\n",
    "data1 = read_file(path1)\n",
    "data2 = read_file(path2)\n",
    "# It's a file encoded with ISO\n",
    "data3 = pd.read_csv(path3, sep=\"\\t\", encoding='ISO-8859-1')\n",
    "\n",
    "data = pd.concat([data1, data2, data3])\n",
    "data.iloc[6:9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ArticleTitle', 'Question', 'Answer', 'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile'],\n",
       "    num_rows: 3998\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data = data.copy()\n",
    "# Transformer en un Dataset Hugging Face\n",
    "dataset = Dataset.from_pandas(copy_data)\n",
    "dataset = dataset.remove_columns(\"__index_level_0__\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Question', 'Answer'],\n",
      "    num_rows: 3998\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "#Diviser les données en ensembles train, validation, test\n",
    "train_df = copy_data.sample(frac=1, random_state=42)\n",
    "remaining_df = copy_data.drop(train_df.index)\n",
    "validation_df = remaining_df.sample(frac=0.25, random_state=42)\n",
    "test_df = remaining_df.drop(validation_df.index)\n",
    "\n",
    "# Créer les ensembles DataSet\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Créer les DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "dataset_dict = dataset_dict.remove_columns(['__index_level_0__', 'ArticleTitle', 'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile'])\n",
    "data_finale = dataset_dict[\"train\"]\n",
    "print(data_finale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Théorie:\n",
    "\n",
    "Pour créer un modèle qui fonctionne comme une FAQ, l'approche la plus courante consiste à utiliser des techniques de recherche de similarité de texte. Cela consiste à identifier quelle question de ton ensemble de données est la plus similaire à la question posée en entrée, puis à renvoyer la réponse correspondante.\n",
    "\n",
    "## Les étapes:\n",
    "\n",
    "__1 - Nettoyage et prétraitement des données :__\n",
    "\n",
    "Nettoyer les questions et réponses (enlever les stop words, la ponctuation, etc.).\n",
    "\n",
    "__2 - Vectorisation des questions :__\n",
    "\n",
    "Convertir les questions en vecteurs numériques. Une méthode classique consiste à utiliser des techniques comme TF-IDF, Word2Vec ou des modèles plus avancés comme les embeddings BERT (Bidirectional Encoder Representations from Transformers) pour obtenir des représentations vectorielles des questions.\n",
    "\n",
    "__3 - Calcul de la similarité :__\n",
    "\n",
    "Utiliser une mesure de similarité, comme la similarité cosinus, pour comparer la question en entrée à toutes les questions de ton ensemble de données et identifier la question la plus proche.\n",
    "\n",
    "__4 - Récupération de la réponse :__\n",
    "\n",
    "Renvoyer la réponse correspondant à la question la plus similaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche TF-IDF et Cos-similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les None de ma base de données vu que lors de l'application de vectorizer.fit_transform ça applique .lower() et avec des None ça retoure des erreurs\n",
    "data = [item for item in data_finale if item[\"Question\"] is not None and item[\"Question\"].strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of questions is: 3961 and len of answers is: 3961\n"
     ]
    }
   ],
   "source": [
    "questions = [item[\"Question\"] for item in data]\n",
    "responses = [item[\"Answer\"] for item in data]\n",
    "print(f\"len of questions is: {len(questions)} and len of answers is: {len(responses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape1: Véctorisation les questions avec TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une fonction pour retourner la réponse basant sur le Cos-similarity\n",
    "\n",
    "def get_answer(question: str) -> str:\n",
    "    \"\"\"La réponse avec TF-IDF fonction\n",
    "\n",
    "    Args:\n",
    "        question (str): la question d'entrée\n",
    "\n",
    "    Returns:\n",
    "        str: La réponse trouvée\n",
    "    \"\"\"    \n",
    "    # Avoir le vector de la question\n",
    "    question_tfidf = vectorizer.transform([question])\n",
    "\n",
    "    # Appliquer le cos similarity avec ma matrice\n",
    "    similarity = cosine_similarity(question_tfidf, tf_idf_matrix).flatten()\n",
    "\n",
    "    # Trouver l'index de la question la plus similaire\n",
    "    closest_question_index = np.argmax(similarity)\n",
    "\n",
    "    # Retourner la réponse associe à cette question\n",
    "    return responses[closest_question_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cymbals are usually included in a drum kit?\n",
      "Réponse: at least 3\n",
      "Question: How many long was Lincoln's formal education?\n",
      "Réponse: 18 months\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "new_question = \"How many cymbals are usually included in a drum kit?\"\n",
    "response = get_answer(new_question)\n",
    "print(f\"Question: {new_question}\\nRéponse: {response}\")\n",
    "\n",
    "question2 = \"How many long was Lincoln's formal education?\"\n",
    "response2 = get_answer(question2)\n",
    "print(f\"Question: {question2}\\nRéponse: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amélioration avec BERT (pour de meilleures performances) :\n",
    "\n",
    "Si tu veux une approche plus avancée avec un meilleur niveau de compréhension sémantique, tu peux utiliser un modèle de type BERT.\n",
    "\n",
    "Voici comment utiliser BERT pour encoder les questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zakaria-Laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Charger le model et le tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir les embeddings BERT\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():  # Désactiver le calcul des gradients pour une évaluation\n",
    "        outputs = model(**inputs)\n",
    "    # Prendre la moyenne des embeddings sur la séquence\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Utiliser squeeze pour réduire la dimension\n",
    "\n",
    "# Encoder les questions\n",
    "question_embeddings = np.array([get_bert_embeddings(q) for q in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que `question_embeddings` soit un tableau NumPy contenant les embeddings\n",
    "np.save('question_embeddings.npy', question_embeddings)\n",
    "\n",
    "# Load le fichier\n",
    "#question_embeddings = np.load('question_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour trouver la réponse avec BERT embeddings\n",
    "def find_answer_bert(new_question):\n",
    "    new_question_embedding = get_bert_embeddings(new_question).reshape(1, -1)\n",
    "    similarities = cosine_similarity(new_question_embedding, question_embeddings).flatten()\n",
    "    closest_question_idx = np.argmax(similarities)\n",
    "    return responses[closest_question_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cymbals are usually included in a drum kit?\n",
      "Réponse: at least 3\n",
      "Question: How many long was Lincoln's formal education?\n",
      "Réponse: 18 months\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation avec BERT\n",
    "new_question = \"How many cymbals are usually included in a drum kit?\"\n",
    "response_bert = find_answer_bert(new_question)\n",
    "print(f\"Question: {new_question}\\nRéponse: {response_bert}\")\n",
    "\n",
    "question2 = \"How many long was Lincoln's formal education?\"\n",
    "response2 = find_answer_bert(question2)\n",
    "print(f\"Question: {question2}\\nRéponse: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métriques d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 70.74%\n"
     ]
    }
   ],
   "source": [
    "# Evaluer mes modèles Avec TFIDF\n",
    "predicted_answers_tfidf = [get_answer(q) for q in questions]\n",
    "\n",
    "y_true = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_tfidf, responses)]\n",
    "y_pred = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_tfidf, responses)]\n",
    "\n",
    "# Calcul des métriques\n",
    "exact_matches = sum(p == e for p, e in zip(predicted_answers_tfidf, responses)) / len(responses) * 100\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Exact Match: {exact_matches:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 70.76%\n"
     ]
    }
   ],
   "source": [
    "# Evaluer mes modèles avec BERT\n",
    "predicted_answers_bert = [find_answer_bert(q) for q in questions]\n",
    "\n",
    "y_true = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_bert, responses)]\n",
    "y_pred = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_bert, responses)]\n",
    "\n",
    "# Calcul des métriques\n",
    "exact_matches = sum(p == e for p, e in zip(predicted_answers_bert, responses)) / len(responses) * 100\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Exact Match: {exact_matches:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------- To be continued -------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dash = \"-\".join(\"\" for x in range(50))\n",
    "print(f\"{dash} To be continued {dash}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
