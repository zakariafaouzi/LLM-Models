{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Les paths de fichiers\n",
    "path1 = r\"C:\\Users\\Zakaria-Laptop\\LLM-Models\\NLP_TFIDF\\DataBase\\S08_question_answer_pairs.txt\"\n",
    "path2 = r\"C:\\Users\\Zakaria-Laptop\\LLM-Models\\NLP_TFIDF\\DataBase\\S09_question_answer_pairs.txt\"\n",
    "path3 = r\"C:\\Users\\Zakaria-Laptop\\LLM-Models\\NLP_TFIDF\\DataBase\\S10_question_answer_pairs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleTitle</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>DifficultyFromQuestioner</th>\n",
       "      <th>DifficultyFromAnswerer</th>\n",
       "      <th>ArticleFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months</td>\n",
       "      <td>medium</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months.</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abraham_Lincoln</td>\n",
       "      <td>When did Lincoln begin his political career?</td>\n",
       "      <td>1832</td>\n",
       "      <td>medium</td>\n",
       "      <td>easy</td>\n",
       "      <td>S08_set3_a4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleTitle                                       Question      Answer  \\\n",
       "6  Abraham_Lincoln  How many long was Lincoln's formal education?   18 months   \n",
       "7  Abraham_Lincoln  How many long was Lincoln's formal education?  18 months.   \n",
       "8  Abraham_Lincoln   When did Lincoln begin his political career?        1832   \n",
       "\n",
       "  DifficultyFromQuestioner DifficultyFromAnswerer  ArticleFile  \n",
       "6                   medium                   easy  S08_set3_a4  \n",
       "7                   medium                 medium  S08_set3_a4  \n",
       "8                   medium                   easy  S08_set3_a4  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: _description_\n",
    "    \"\"\"    \n",
    "    return pd.read_csv(path, sep=\"\t\")\n",
    "\n",
    "data1 = read_file(path1)\n",
    "data2 = read_file(path2)\n",
    "# It's a file encoded with ISO\n",
    "data3 = pd.read_csv(path3, sep=\"\\t\", encoding='ISO-8859-1')\n",
    "\n",
    "data = pd.concat([data1, data2, data3])\n",
    "data.iloc[6:9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ArticleTitle', 'Question', 'Answer', 'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile'],\n",
       "    num_rows: 3998\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_data = data.copy()\n",
    "# Transformer en un Dataset Hugging Face\n",
    "dataset = Dataset.from_pandas(copy_data)\n",
    "dataset = dataset.remove_columns(\"__index_level_0__\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Question', 'Answer'],\n",
      "    num_rows: 3998\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "#Diviser les données en ensembles train, validation, test\n",
    "train_df = copy_data.sample(frac=1, random_state=42)\n",
    "remaining_df = copy_data.drop(train_df.index)\n",
    "validation_df = remaining_df.sample(frac=0.25, random_state=42)\n",
    "test_df = remaining_df.drop(validation_df.index)\n",
    "\n",
    "# Créer les ensembles DataSet\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Créer les DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset,\n",
    "})\n",
    "dataset_dict = dataset_dict.remove_columns(['__index_level_0__', 'ArticleTitle', 'DifficultyFromQuestioner', 'DifficultyFromAnswerer', 'ArticleFile'])\n",
    "data_finale = dataset_dict[\"train\"]\n",
    "print(data_finale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Théorie:\n",
    "\n",
    "Pour créer un modèle qui fonctionne comme une FAQ, l'approche la plus courante consiste à utiliser des techniques de recherche de similarité de texte. Cela consiste à identifier quelle question de ton ensemble de données est la plus similaire à la question posée en entrée, puis à renvoyer la réponse correspondante.\n",
    "\n",
    "## Les étapes:\n",
    "\n",
    "__1 - Nettoyage et prétraitement des données :__\n",
    "\n",
    "Nettoyer les questions et réponses (enlever les stop words, la ponctuation, etc.).\n",
    "\n",
    "__2 - Vectorisation des questions :__\n",
    "\n",
    "Convertir les questions en vecteurs numériques. Une méthode classique consiste à utiliser des techniques comme TF-IDF, Word2Vec ou des modèles plus avancés comme les embeddings BERT (Bidirectional Encoder Representations from Transformers) pour obtenir des représentations vectorielles des questions.\n",
    "\n",
    "__3 - Calcul de la similarité :__\n",
    "\n",
    "Utiliser une mesure de similarité, comme la similarité cosinus, pour comparer la question en entrée à toutes les questions de ton ensemble de données et identifier la question la plus proche.\n",
    "\n",
    "__4 - Récupération de la réponse :__\n",
    "\n",
    "Renvoyer la réponse correspondant à la question la plus similaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche TF-IDF et Cos-similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les None de ma base de données vu que lors de l'application de vectorizer.fit_transform ça applique .lower() et avec des None ça retoure des erreurs\n",
    "data = [item for item in data_finale if item[\"Question\"] is not None and item[\"Question\"].strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of questions is: 3961 and len of answers is: 3961\n"
     ]
    }
   ],
   "source": [
    "questions = [item[\"Question\"] for item in data]\n",
    "responses = [item[\"Answer\"] for item in data]\n",
    "print(f\"len of questions is: {len(questions)} and len of answers is: {len(responses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etape1: Véctorisation les questions avec TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_matrix = vectorizer.fit_transform(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une fonction pour retourner la réponse basant sur le Cos-similarity\n",
    "\n",
    "def get_answer(question: str) -> str:\n",
    "    \"\"\"La réponse avec TF-IDF fonction\n",
    "\n",
    "    Args:\n",
    "        question (str): la question d'entrée\n",
    "\n",
    "    Returns:\n",
    "        str: La réponse trouvée\n",
    "    \"\"\"    \n",
    "    # Avoir le vector de la question\n",
    "    question_tfidf = vectorizer.transform([question])\n",
    "\n",
    "    # Appliquer le cos similarity avec ma matrice\n",
    "    similarity = cosine_similarity(question_tfidf, tf_idf_matrix).flatten()\n",
    "\n",
    "    # Trouver l'index de la question la plus similaire\n",
    "    closest_question_index = np.argmax(similarity)\n",
    "\n",
    "    # Retourner la réponse associe à cette question\n",
    "    return responses[closest_question_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cymbals are usually included in a drum kit?\n",
      "Réponse: at least 3\n",
      "Question: How many long was Lincoln's formal education?\n",
      "Réponse: 18 months\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "new_question = \"How many cymbals are usually included in a drum kit?\"\n",
    "response = get_answer(new_question)\n",
    "print(f\"Question: {new_question}\\nRéponse: {response}\")\n",
    "\n",
    "question2 = \"How many long was Lincoln's formal education?\"\n",
    "response2 = get_answer(question2)\n",
    "print(f\"Question: {question2}\\nRéponse: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amélioration avec BERT (pour de meilleures performances) :\n",
    "\n",
    "Si tu veux une approche plus avancée avec un meilleur niveau de compréhension sémantique, tu peux utiliser un modèle de type BERT.\n",
    "\n",
    "Voici comment utiliser BERT pour encoder les questions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zakaria-Laptop\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Charger le model et le tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir les embeddings BERT\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():  # Désactiver le calcul des gradients pour une évaluation\n",
    "        outputs = model(**inputs)\n",
    "    # Prendre la moyenne des embeddings sur la séquence\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Utiliser squeeze pour réduire la dimension\n",
    "\n",
    "# Encoder les questions\n",
    "question_embeddings = np.array([get_bert_embeddings(q) for q in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que `question_embeddings` soit un tableau NumPy contenant les embeddings\n",
    "np.save('question_embeddings.npy', question_embeddings)\n",
    "\n",
    "# Load le fichier\n",
    "#question_embeddings = np.load('question_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour trouver la réponse avec BERT embeddings\n",
    "def find_answer_bert(new_question):\n",
    "    new_question_embedding = get_bert_embeddings(new_question).reshape(1, -1)\n",
    "    similarities = cosine_similarity(new_question_embedding, question_embeddings).flatten()\n",
    "    closest_question_idx = np.argmax(similarities)\n",
    "    return responses[closest_question_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many cymbals are usually included in a drum kit?\n",
      "Réponse: at least 3\n",
      "Question: How many long was Lincoln's formal education?\n",
      "Réponse: 18 months\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation avec BERT\n",
    "new_question = \"How many cymbals are usually included in a drum kit?\"\n",
    "response_bert = find_answer_bert(new_question)\n",
    "print(f\"Question: {new_question}\\nRéponse: {response_bert}\")\n",
    "\n",
    "question2 = \"How many long was Lincoln's formal education?\"\n",
    "response2 = find_answer_bert(question2)\n",
    "print(f\"Question: {question2}\\nRéponse: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métriques d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 70.74%\n"
     ]
    }
   ],
   "source": [
    "# Evaluer mes modèles Avec TFIDF\n",
    "predicted_answers_tfidf = [get_answer(q) for q in questions]\n",
    "\n",
    "y_true = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_tfidf, responses)]\n",
    "y_pred = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_tfidf, responses)]\n",
    "\n",
    "# Calcul des métriques\n",
    "exact_matches = sum(p == e for p, e in zip(predicted_answers_tfidf, responses)) / len(responses) * 100\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Exact Match: {exact_matches:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match: 70.76%\n"
     ]
    }
   ],
   "source": [
    "# Evaluer mes modèles avec BERT\n",
    "predicted_answers_bert = [find_answer_bert(q) for q in questions]\n",
    "\n",
    "y_true = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_bert, responses)]\n",
    "y_pred = [1 if ans == expected else 0 for ans, expected in zip(predicted_answers_bert, responses)]\n",
    "\n",
    "# Calcul des métriques\n",
    "exact_matches = sum(p == e for p, e in zip(predicted_answers_bert, responses)) / len(responses) * 100\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Exact Match: {exact_matches:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------- To be continued -------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dash = \"-\".join(\"\" for x in range(50))\n",
    "print(f\"{dash} To be continued {dash}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
